{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "<h3>Task 1-3: creating the layer and network objects, with read- and evaluate methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self,weight_file,bias_file):\n",
    "        self.weight_file = weight_file\n",
    "        self.bias_file = bias_file\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "    def read_data(self):\n",
    "        self.weight = np.loadtxt(self.weight_file)\n",
    "        self.bias = np.loadtxt(self.bias_file)\n",
    "\n",
    "class Network:\n",
    "    def __init__(self,layers):\n",
    "        assert isinstance(layers[0],Layer)\n",
    "        self.layers = layers\n",
    "        self.activation = lambda x: np.maximum(0,x)\n",
    "\n",
    "    def read_network_data(self):\n",
    "        for layer in self.layers:\n",
    "            layer.read_data()\n",
    "\n",
    "    def evaluate(self,input):\n",
    "        assert input.shape[0] == self.layers[0].weight.shape[1], f\"Input size must match network input size: {self.layers[0].weight.shape[1]}\"\n",
    "        state_vector = input\n",
    "        for layer in self.layers:\n",
    "            state_vector = self.activation(layer.weight @ state_vector + layer.bias)\n",
    "        return state_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading in the matrix data and initialising the network</h3>\n",
    "\n",
    "NB! i am storing the data in a folder called \"exercise6_data\", modify the code to work on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "cwd = Path.cwd()\n",
    "data_dir = cwd / 'exercise6_data'\n",
    "\n",
    "weight_files = []; bias_files = []\n",
    "\n",
    "# Defining the pattern of the files we want to read\n",
    "W_pattern = re.compile(r'W_[0-9]+.txt')\n",
    "b_pattern = re.compile(r'b_[0-9]+.txt')\n",
    "\n",
    "for file in data_dir.glob('*.txt'):\n",
    "    if W_pattern.match(file.name):\n",
    "        weight_files.append(file)\n",
    "    elif b_pattern.match(file.name):\n",
    "        bias_files.append(file)\n",
    "\n",
    "layers = [Layer(w,b) for w,b in zip(weight_files,bias_files)]\n",
    "\n",
    "network = Network(layers)\n",
    "network.read_network_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4: code to read the image data (provided by Jonas)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "def get_mnist():\n",
    "    return datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "def return_image(image_index, mnist_dataset):\n",
    "    # Get the image and its corresponding label\n",
    "    image, label = mnist_dataset[image_index]\n",
    "\n",
    "    # Now, you have the image as a PyTorch tensor.\n",
    "    # You can access its data as a matrix using .detach().numpy()\n",
    "    image_matrix = image[0].detach().numpy()  # Grayscale image, so we select the first channel (index 0)\n",
    "\n",
    "    return image_matrix.reshape(image_matrix.size), image_matrix, label\n",
    "\n",
    "def read_from_file(name=data_dir / \"image_19961.txt\"):\n",
    "        x = np.zeros(28 * 28)\n",
    "        with open(name) as file:\n",
    "                for i, line in enumerate(file):\n",
    "                    # split and convert values to floats\n",
    "                    x[i * 28 : (i+1)*28] = [float(value) for value in line.strip().split()]\n",
    "\n",
    "# Choose an index to select one of the images\n",
    "image_index = 19961\n",
    "mnist_dataset = get_mnist()\n",
    "x, image, label = return_image(image_index, mnist_dataset) # This here reads image {image_index} from the mnist dataset.\n",
    "x_file = read_from_file() # In case you were not able to install torchvision, you can use this read_from_file function\n",
    "\n",
    "print(f\"Image {image_index} shows the number {label}\")\n",
    "print(f\"The pixels of this image (collected in a vector) are \\n {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 5: Get the network response to image 19961 in the MNIST dataset</h3>\n",
    "\n",
    "The value \"x\" in the above program is the image vector, we pass this to the networks evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response vector of the network is:\n",
      "y_0 = 0.0\n",
      "y_1 = 0.0\n",
      "y_2 = 757.0263547524963\n",
      "y_3 = 780.126158687573\n",
      "y_4 = 1802.9654413263854\n",
      "y_5 = 1006.2120253052831\n",
      "y_6 = 763.2919819585368\n",
      "y_7 = 267.6888560392754\n",
      "y_8 = 849.7265384811928\n",
      "y_9 = 1454.8858175200617\n"
     ]
    }
   ],
   "source": [
    "response_vector = network.evaluate(x)\n",
    "\n",
    "print(f\"The response vector of the network is:\")\n",
    "for i in range(len(response_vector)):\n",
    "    print(f\"y_{i} = {response_vector[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
