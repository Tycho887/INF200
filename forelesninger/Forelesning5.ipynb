{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETS\n",
    "\n",
    "sets in python are similar to their mathematical definition; that is, they are a collection of items like numbers or objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set([1,2,3])\n",
    "s = {1,2,3}\n",
    "# we can build sets using set comprehensions\n",
    "s2 = {x**2 for x in range(10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use operands on such sets\n",
    "* Combine sets: c = s | b\n",
    "* Combine sets as union: c = s & b\n",
    "* s without b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odd nonprime numbers {1, 9, 15}\n",
      "odd prime numbers {3, 5, 7, 11, 13, 17, 19}\n"
     ]
    }
   ],
   "source": [
    "numbers = 21\n",
    "odds = {num for num in range(20) if num % 2 == 1}\n",
    "# now we want to find a set of all prime numbers less than the varaible numbers\n",
    "# we want to accomplish this using a set comprehension\n",
    "\n",
    "primes = {2,3,5,7,11,13,17,19}\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2,n):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(\"odd nonprime numbers\", odds - primes)\n",
    "print(\"odd prime numbers\", primes & odds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: A simple overview\n",
    "\n",
    "Neural newtworks work by taking a input, doing a set of \"blackbox\" operations before returning a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy: Matrix-Vector algebra\n",
    "\n",
    "We can define matrices and vectors in numpy, and then do linear-algebra operands on these objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01238686 0.42541799]\n",
      " [0.19112698 0.91190371]]\n",
      "[0.26246584 0.12425462]\n",
      "[[0.00325113 0.05286015]\n",
      " [0.0501643  0.11330825]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "W = np.matrix([[0,1],[2,3]])\n",
    "W1 = np.empty((2,2))\n",
    "W2 = np.random.rand(2,2)\n",
    "x = np.empty(2)\n",
    "x1 = np.random.rand(2)\n",
    "print(W2)\n",
    "print(x1)\n",
    "print(W2*x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12425462 0.89769554]\n",
      "[[0.12425462 0.89769554]]\n"
     ]
    }
   ],
   "source": [
    "def mult(W,x):\n",
    "    m,n = W.shape\n",
    "    working_vector = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            working_vector[i] += W[i,j]*x[j]\n",
    "    return working_vector\n",
    "\n",
    "print(mult(W,x1))\n",
    "# we want to print the matrix-vector product of W and x1 using numpy\n",
    "print(W @ x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear algebra in Numpy\n",
    "\n",
    "* Use @ when doing matrix-vector products\n",
    "* Use W.T to get the transposed matrix/vector\n",
    "* Use x.norm to get the euclidian norm of a vector, that is the \"length\" of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primitive neural network\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image_size = 8**2\n",
    "returns = 10\n",
    "\n",
    "input_vector = np.random.rand(image_size)\n",
    "\n",
    "weights_1 = np.random.rand(10,image_size)\n",
    "weights_2 = np.random.rand(10,image_size)\n",
    "\n",
    "bias_1 = np.random.rand(returns)\n",
    "bias_2 = np.random.rand(returns)\n",
    "\n",
    "def sigma(x):\n",
    "    if x < 0:\n",
    "        return np.sin(x)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "sigma_vec = np.vectorize(sigma)\n",
    "\n",
    "def single_layer(weights, input_vector, bias):\n",
    "    return sigma_vec(weights @ input_vector + bias)\n",
    "\n",
    "def neural_network(input_vector, weights_1,weights_2, bias_1, bias_2):\n",
    "    y_1 = single_layer(weights_1, input_vector, bias_1)\n",
    "    y_2 = single_layer(weights_2, y_1, bias_2)\n",
    "\n",
    "one_layer = single_layer(weights_1, input_vector, bias_1)\n",
    "\n",
    "\n",
    "#%timeit z = layer(weights, input_vector, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear algebra functions\n",
    "\n",
    "* When we have a linear system consisting of a matrix W and vector b, we can solve the system by using np.linalg.solve\n",
    "* You can QR factorize a matrix by using: Q, R = np.linalg.qr(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.   1.5]\n",
      "[[ 1.00000000e+00 -5.84964249e-17]\n",
      " [-5.84964249e-17  1.00000000e+00]] the matrix Q is orthonormal\n"
     ]
    }
   ],
   "source": [
    "b = np.array([1,0])\n",
    "W = np.matrix([[1,2],[3,4]])\n",
    "# we want to solve this system using linalg.solve\n",
    "x = np.linalg.solve(W,b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -1.24172344e-19  1.02624633e-17 ... -2.77555756e-17\n",
      "  -5.89805982e-17 -7.28583860e-17]\n",
      " [-1.24172344e-19  1.00000000e+00  1.45333927e-17 ... -2.42861287e-17\n",
      "  -6.93889390e-17  4.16333634e-17]\n",
      " [ 1.02624633e-17  1.45333927e-17  1.00000000e+00 ...  0.00000000e+00\n",
      "   8.67361738e-18 -6.93889390e-17]\n",
      " ...\n",
      " [-2.77555756e-17 -2.42861287e-17  0.00000000e+00 ...  1.00000000e+00\n",
      "  -2.47609287e-16  1.24900090e-16]\n",
      " [-5.89805982e-17 -6.93889390e-17  8.67361738e-18 ... -2.47609287e-16\n",
      "   1.00000000e+00 -1.04083409e-16]\n",
      " [-7.28583860e-17  4.16333634e-17 -6.93889390e-17 ...  1.24900090e-16\n",
      "  -1.04083409e-16  1.00000000e+00]] the matrix Q is orthonormal\n"
     ]
    }
   ],
   "source": [
    "m = 100\n",
    "\n",
    "b = np.random.rand(m)\n",
    "W = np.random.rand(m,m)\n",
    "\n",
    "Q,R = np.linalg.qr(W)\n",
    "\n",
    "print(Q.T @ Q, \"the matrix Q is orthonormal\")\n",
    "\n",
    "# QR factorization makes solving linear systems a lot faster, O(n^2) instead of O(n^3)\n",
    "\n",
    "# the solution of the above system then becomes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low rank approximation\n",
    "\n",
    "A matrix W can be approximated by a product of three smaller orthonormal bases: U, V and S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S , V = np.linalg.svd(W)\n",
    "# svd means \"singular value decomposition\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
