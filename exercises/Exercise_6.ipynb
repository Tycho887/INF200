{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "<h3>Task 1-3: creating the layer and network objects, with read- and evaluate methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self,weight_file,bias_file,cols=None,rows=None):\n",
    "        self.weight_file = weight_file\n",
    "        self.bias_file = bias_file\n",
    "        try:\n",
    "            self.weight = np.random.rand(rows,cols)\n",
    "            self.bias = np.random.rand(rows)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    def read_data(self):\n",
    "        self.weight = np.loadtxt(self.weight_file)\n",
    "        self.bias = np.loadtxt(self.bias_file)\n",
    "\n",
    "class Network:\n",
    "    def __init__(self,layers):\n",
    "        assert isinstance(layers[0],Layer)\n",
    "        self.layers = layers\n",
    "        self.activation = lambda x: np.maximum(0,x)\n",
    "\n",
    "    def read_network_data(self):\n",
    "        for layer in self.layers:\n",
    "            layer.read_data()\n",
    "\n",
    "    def evaluate(self,input):\n",
    "        assert input.shape[0] == self.layers[0].weight.shape[1], f\"Input size must match network input size: {self.layers[0].weight.shape[1]}\"\n",
    "        state_vector = input\n",
    "        for layer in self.layers:\n",
    "            state_vector = self.activation(layer.weight @ state_vector + layer.bias)\n",
    "        return state_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading in the matrix data and initialising the network</h3>\n",
    "\n",
    "NB! i am storing the data in a folder called \"exercise6_data\", modify the code to work on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "cwd = Path.cwd()\n",
    "#we want to go to the parent folder, then into the 'exercise6_data' folder\n",
    "data_dir = cwd.parent / 'data'\n",
    "#data_dir = cwd /  /'exercise6_data'\n",
    "\n",
    "weight_files = []; bias_files = []\n",
    "\n",
    "# Defining the pattern of the files we want to read\n",
    "W_pattern = re.compile(r'W_[0-9]+.txt')\n",
    "b_pattern = re.compile(r'b_[0-9]+.txt')\n",
    "\n",
    "for file in data_dir.glob('*.txt'):\n",
    "    if W_pattern.match(file.name):\n",
    "        weight_files.append(file)\n",
    "    elif b_pattern.match(file.name):\n",
    "        bias_files.append(file)\n",
    "\n",
    "layers = [Layer(w,b) for w,b in zip(weight_files,bias_files)]\n",
    "\n",
    "network = Network(layers)\n",
    "network.read_network_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4: code to read the image data (provided by Jonas)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    return datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "def return_image(image_index, mnist_dataset):\n",
    "    # Get the image and its corresponding label\n",
    "    image, label = mnist_dataset[image_index]\n",
    "\n",
    "    # Now, you have the image as a PyTorch tensor.\n",
    "    # You can access its data as a matrix using .detach().numpy()\n",
    "    image_matrix = image[0].detach().numpy()  # Grayscale image, so we select the first channel (index 0)\n",
    "\n",
    "    return image_matrix.reshape(image_matrix.size), image_matrix, label\n",
    "\n",
    "def read_from_file(name=data_dir / \"image_19961.txt\"):\n",
    "        x = np.zeros(28 * 28)\n",
    "        with open(name) as file:\n",
    "                for i, line in enumerate(file):\n",
    "                    # split and convert values to floats\n",
    "                    x[i * 28 : (i+1)*28] = [float(value) for value in line.strip().split()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 19967 shows the number 3\n"
     ]
    }
   ],
   "source": [
    "# Choose an index to select one of the images\n",
    "image_index = 19967\n",
    "mnist_dataset = get_mnist()\n",
    "x, image, label = return_image(image_index, mnist_dataset) # This here reads image {image_index} from the mnist dataset.\n",
    "x_file = read_from_file() # In case you were not able to install torchvision, you can use this read_from_file function\n",
    "\n",
    "print(f\"Image {image_index} shows the number {label}\")\n",
    "#print(f\"The pixels of this image (collected in a vector) are \\n {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 5: Get the network response to image 19961 in the MNIST dataset</h3>\n",
    "\n",
    "The value \"x\" in the above program, is the image vector; we pass this to the network's evaluation method to get the response.\n",
    "We then divide by the maximum vector value to get make the other values in the vector, to represent the certainty relative to the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response vector of the network is: 3\n"
     ]
    }
   ],
   "source": [
    "response_vector = network.evaluate(x)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(f\"The response vector of the network is: {np.argmax(response_vector)}\")\n",
    "# for i in range(len(response_vector)):\n",
    "#     print(f\"y_{i} = {response_vector[i] / np.max(response_vector):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
